# -*- coding: utf-8 -*-
"""EE769_Project_new(seq_train_2_with_reduced_with_400images).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C3vgy0N1LFPN6tN7U-VwlcAfEQhapumI

###MODEL
"""

import tensorflow as tf
import numpy as np
from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, UpSampling2D
from tensorflow.keras.models import Model

def conv_weights_init(input, num_filters, filter_size):
  in_channels = np.array(input.get_shape())[-1]
  weights_shape = [filter_size, filter_size, in_channels, num_filters]
  weights_init = tf.Variable(tf.random.normal(weights_shape, mean = 0.0, stddev = 0.1, dtype=tf.dtypes.float32, seed = 224), dtype=tf.dtypes.float32)
  return weights_init

def leaky_relu(input, alpha = 0.2):
  return tf.maximum(alpha*input, input)

def maxpool(input, n):
  return tf.nn.max_pool(input, ksize = [1, n, n, 1], strides = [1, n, n, 1], padding = 'VALID')

def instance_norm_(input):
  var_shape = [np.array(tf.shape(input))[3]]

  mu, var = tf.compat.v1.nn.moments(input, [1,2], keep_dims=True)
  shift = tf.Variable(tf.zeros(var_shape))
  scale = tf.Variable(tf.ones(var_shape))

  epsilon = 1e-3
  normalized = (input-mu)/(var + epsilon)**(.5)

  return scale * normalized + shift

def conv_layer(input, num_filters, filter_size, strides, relu = True, padding = 'SAME', instance_norm = False):
  # weights_init = conv_weights_init(input, num_filters, filter_size)
  # strides_shape = [1, strides, strides, 1]
  # bias = tf.Variable(tf.constant(0.01, shape = [num_filters]), dtype=tf.dtypes.float32)
  # input = tf.nn.conv2d(input, weights_init, strides_shape, padding = padding) + bias
  # #input = Conv2D(num_filters, filter_size, strides)(input) + bias
  # if instance_norm:
  #   input = instance_norm_(input)
  # if relu:
  #   input = leaky_relu(input)
  # return input
  if relu:
    x = Conv2D(num_filters, (filter_size, filter_size), padding = padding, strides = strides, activation = 'relu')(input) #= tf.keras.layers.LeakyReLU(alpha = 0.2)
    return x
  x = Conv2D(num_filters, (filter_size, filter_size), padding = padding, strides = strides)(input)
  return x

def conv_transpose(input, num_filters, filter_size, strides):
  # weights_init = conv_weights_init(input, num_filters, filter_size)
  # strides_shape = [1, strides, strides, 1]
  # in_shape = tf.shape(input)
  # out_shape = tf.stack([in_shape[0], in_shape[1] * strides, in_shape[2] * strides, num_filters])
  # input = tf.nn.conv2d_transpose(input, weights_init, out_shape, strides_shape)
  # #input = Conv2DTranspose(num_filters, filter_size, strides)(input)
  # return leaky_relu(input)

  x = Conv2DTranspose(num_filters, (filter_size, filter_size), strides = strides, padding = 'same')(input)
  return x

def conv_multiple(input, max_size, num_filters, instance_norm):
  conv_3a = conv_layer(input, num_filters, 3, 1, instance_norm = instance_norm)
  conv_3b = conv_layer(conv_3a, num_filters, 3, 1, instance_norm = instance_norm)

  output = conv_3b

  if max_size >= 5:
    conv_5a = conv_layer(output, num_filters, 5, 1, instance_norm = instance_norm)
    conv_5b = conv_layer(conv_5a, num_filters, 5, 1, instance_norm = instance_norm)

    #output = tf.concat([output, conv_5b], 3)
    output = Concatenate()([output, conv_5b])
  
  if max_size >= 7:
    conv_7a = conv_layer(output, num_filters, 5, 1, instance_norm = instance_norm)
    conv_7b = conv_layer(conv_7a, num_filters, 5, 1, instance_norm = instance_norm)

    #output = tf.concat([output, conv_7b], 3)
    output = Concatenate()([output, conv_7b])
  
  if max_size == 9:
    conv_9a = conv_layer(output, num_filters, 5, 1, instance_norm = instance_norm)
    conv_9b = conv_layer(conv_9a, num_filters, 5, 1, instance_norm = instance_norm)

    #output = tf.concat([output, conv_9b], 3)
    output = Concatenate()([output, conv_9b])
  
  return output

def PyNet(input_shape, instance_norm = True, instance_norm_level3 = False):
  input = Input(input_shape)
  #with tf.compat.v1.variable_scope("generator"):

  space2depth_l0 = tf.nn.space_to_depth(input, 2)

  conv_l3_i1 = conv_multiple(space2depth_l0, 3, num_filters = 32, instance_norm = False)
  pool3 = maxpool(conv_l3_i1, 2)
  conv_l4_i1 = conv_multiple(pool3, 3, num_filters = 64, instance_norm = instance_norm)
  pool4 = maxpool(conv_l4_i1, 2)
  conv_l5_i1 = conv_multiple(pool4, 3, num_filters = 128, instance_norm = instance_norm)
  pool5 = maxpool(conv_l5_i1, 2)
  conv_l6_i1 = conv_multiple(pool5, 3, num_filters = 256, instance_norm = instance_norm)
  pool6 = maxpool(conv_l6_i1, 2)

  conv_l7_i1 = conv_multiple(pool6, 3, num_filters = 512, instance_norm = instance_norm)
  conv_l7_i2 = conv_multiple(conv_l7_i1, 3, num_filters = 512, instance_norm = instance_norm) + conv_l7_i1
  conv_l7_i3 = conv_multiple(conv_l7_i2, 3, num_filters = 512, instance_norm = instance_norm) + conv_l7_i2
  conv_l7_i4 = conv_multiple(conv_l7_i3, 3, num_filters = 512, instance_norm = instance_norm)

  conv_t6a = conv_transpose(conv_l7_i4, 256, 3, 2)      
  conv_t6b = conv_transpose(conv_l7_i4, 256, 3, 2)   

  conv_l7_out = conv_layer(conv_l7_i4, 3, 3, 1, relu=False, instance_norm=False)
  output_l7 = tf.nn.tanh(conv_l7_out) * 0.58 + 0.5

  #---------------------------------------------------------------------------------------------------------------------

  #conv_l6_i2 = tf.concat([conv_l6_i1, conv_t6a], 3)
  conv_l6_i2 = Concatenate()([conv_l6_i1, conv_t6a])
  conv_l6_i3 = conv_multiple(conv_l6_i2, 3, num_filters=256, instance_norm=instance_norm)
  conv_l6_i4 = conv_multiple(conv_l6_i3, 3, num_filters=256, instance_norm=instance_norm) + conv_l6_i3
  conv_l6_i5 = conv_multiple(conv_l6_i4, 3, num_filters=256, instance_norm=instance_norm) + conv_l6_i4
  #conv_l6_i6 = tf.concat([(conv_multiple(conv_l6_i5, 3, num_filters=256, instance_norm=instance_norm), conv_t6b)], 3)
  conv_l6_i6 = Concatenate()([conv_multiple(conv_l6_i5, 3, num_filters=256, instance_norm=instance_norm), conv_t6b])

  conv_l6_i7 = conv_multiple(conv_l6_i6, 3, num_filters=256, instance_norm=instance_norm)

  conv_t5a = conv_transpose(conv_l6_i7, 128, 3, 2)      
  conv_t5b = conv_transpose(conv_l6_i7, 128, 3, 2)      

  conv_l6_out = conv_layer(conv_l6_i7, 3, 3, 1, relu=False, instance_norm=False)
  output_l6 = tf.nn.tanh(conv_l6_out) * 0.58 + 0.5

  # -----------------------------------------------------------------------------------------------------------------------

  #conv_l5_i2 = tf.concat([conv_l5_i1, conv_t5a], 3)
  conv_l5_i2 = Concatenate()([conv_l5_i1, conv_t5a])
  conv_l5_i3 = conv_multiple(conv_l5_i2, 5, num_filters = 128, instance_norm = instance_norm) + conv_l5_i2
  conv_l5_i4 = conv_multiple(conv_l5_i3, 5, num_filters = 128, instance_norm = instance_norm) + conv_l5_i3
  conv_l5_i5 = conv_multiple(conv_l5_i4, 5, num_filters = 128, instance_norm = instance_norm) + conv_l5_i4
  #conv_l5_i6 = tf.concat([conv_multiple(conv_l5_i5, 5, num_filters = 128, instance_norm = instance_norm), conv_l5_i1], 3)
  conv_l5_i6 = Concatenate()([conv_multiple(conv_l5_i5, 5, num_filters = 128, instance_norm = instance_norm), conv_l5_i1])
  #conv_l5_i7 = tf.concat([conv_l5_i6, conv_t5b], 3)
  conv_l5_i7 = Concatenate()([conv_l5_i6, conv_t5b])

  conv_l5_i8 = conv_multiple(conv_l5_i7, 3, num_filters = 128, instance_norm = instance_norm)

  conv_t4a = conv_transpose(conv_l5_i8, 64, 3, 2)
  conv_t4b = conv_transpose(conv_l5_i8, 64, 3, 2)

  conv_l5_out = conv_layer(conv_l5_i8, 3, 3, 1, relu = False, instance_norm = False)
  output_l5 = tf.nn.tanh(conv_l5_out) * 0.58 + 0.5

  # ----------------------------------------------------------------------------------------------------------------------------------

  #conv_l4_i2 = tf.concat([conv_l4_i1, conv_t4a], 3)
  conv_l4_i2 = Concatenate()([conv_l4_i1, conv_t4a])
  #conv_l4_i3 = tf.concat([conv_multiple(conv_l4_i2, 5, num_filters = 64, instance_norm = instance_norm), conv_l4_i1], 3)
  conv_l4_i3 = Concatenate()([conv_multiple(conv_l4_i2, 5, num_filters = 64, instance_norm = instance_norm), conv_l4_i1])

  conv_l4_i4 = conv_multiple(conv_l4_i3, 7, num_filters = 64, instance_norm = instance_norm) + conv_l4_i3
  conv_l4_i5 = conv_multiple(conv_l4_i4, 7, num_filters = 64, instance_norm = instance_norm) + conv_l4_i4
  conv_l4_i6 = conv_multiple(conv_l4_i5, 7, num_filters = 64, instance_norm = instance_norm) + conv_l4_i5
  #conv_l4_i7 = tf.concat([conv_multiple(conv_l4_i6, 7, num_filters = 64, instance_norm = instance_norm), conv_l4_i1], 3)
  conv_l4_i7 = Concatenate()([conv_multiple(conv_l4_i6, 7, num_filters = 64, instance_norm = instance_norm), conv_l4_i1])

  #conv_l4_i8 = tf.concat([conv_multiple(conv_l4_i7, 5, num_filters = 64, instance_norm = instance_norm), conv_t4b], 3)
  conv_l4_i8 = Concatenate()([conv_multiple(conv_l4_i7, 5, num_filters = 64, instance_norm = instance_norm), conv_t4b])
  conv_l4_i9 = conv_multiple(conv_l4_i8, 3, num_filters = 64, instance_norm = instance_norm)

  conv_t3a = conv_transpose(conv_l4_i9, 32, 3, 2)
  conv_t3b = conv_transpose(conv_l4_i9, 32, 3, 2)

  conv_l4_out = conv_layer(conv_l4_i9, 3, 3, 1, relu = False, instance_norm = False)
  output_l4 = tf.nn.tanh(conv_l4_out) * 0.58 + 0.5    

  # ---------------------------------------------------------------------------------------------------------------------
  
  #conv_l3_i2 = tf.concat([conv_l3_i1, conv_t3a], 3)
  conv_l3_i2 = Concatenate()([conv_l3_i1, conv_t3a])
  #conv_l3_i3 = tf.concat([conv_multiple(conv_l3_i2, 5, num_filters = 32, instance_norm = False), conv_l3_i1], 3)
  conv_l3_i3 = Concatenate()([conv_multiple(conv_l3_i2, 5, num_filters = 32, instance_norm = False), conv_l3_i1])

  conv_l3_i4 = conv_multiple(conv_l3_i3, 7, num_filters = 32, instance_norm = False)
  conv_l3_i5 = conv_multiple(conv_l3_i4, 9, num_filters = 32, instance_norm = instance_norm_level3)
  conv_l3_i6 = conv_multiple(conv_l3_i5, 9, num_filters = 32, instance_norm = instance_norm_level3) + conv_l3_i5
  conv_l3_i7 = conv_multiple(conv_l3_i6, 9, num_filters = 32, instance_norm = instance_norm_level3) + conv_l3_i6
  conv_l3_i8 = conv_multiple(conv_l3_i7, 9, num_filters = 32, instance_norm = instance_norm_level3) + conv_l3_i7

  #conv_l3_i9 = tf.concat([conv_multiple(conv_l3_i8, 7, num_filters = 32, instance_norm = False), conv_l3_i1], 3)
  conv_l3_i9 = Concatenate()([conv_multiple(conv_l3_i8, 7, num_filters = 32, instance_norm = False), conv_l3_i1])
  #conv_l3_i10 = tf.concat([conv_multiple(conv_l3_i9, 5, num_filters = 32, instance_norm = False), conv_t3b], 3)
  conv_l3_i10 = Concatenate()([conv_multiple(conv_l3_i9, 5, num_filters = 32, instance_norm = False), conv_t3b])
  #conv_l3_i11 = tf.concat([conv_l3_i10, conv_l3_i1], 3)
  conv_l3_i11 = Concatenate()([conv_l3_i10, conv_l3_i1])
  conv_l3_i12 = conv_multiple(conv_l3_i11, 3, num_filters = 32, instance_norm = False)

  conv_l3_out = conv_layer(conv_l3_i12, 3, 3, 1, relu = False, instance_norm = False)
  output_l3 = tf.nn.tanh(conv_l3_out) * 0.58 + 0.5 

  # --------------------------------------------------------------------------------------------------------------
  
  conv_l2 = conv_transpose(conv_l3_i12, 8, 3, 2)
  conv_l2_out = conv_layer(conv_l2, 3, 3, 1, relu = False, instance_norm = False)
  output_l2 = tf.nn.tanh(conv_l2_out) * 0.58 + 0.5

  conv_l1 = conv_transpose(conv_l2_out, 3, 3, 2)
  conv_l1_out = conv_layer(conv_l1, 3, 3, 1, relu = False, instance_norm = False)

  output_l1 = tf.nn.tanh(conv_l1_out) * 0.58 + 0.5
  outputs = [output_l1, output_l2, output_l3, output_l4, output_l5, output_l6, output_l7]
  model = Model(input, output_l1)
  #return output_l1, output_l2, output_l3, output_l4, output_l5, output_l6, output_l7
  return model

import tensorflow.keras.backend as K
def loss_function(input, target):
  # loss = tf.zeros((2,1))
  # for i in range(2):
  #   loss[i] = float(1) - tf.image.ssim(input[i], target[i], max_val = 1.0) + K.mean(K.abs(input[i] - target[i]), axis = -1)
  # loss = K.sum(loss, axis = -1)
  loss = float(1) - tf.image.ssim(input, target, max_val = 1.0) + K.mean(K.abs(input - target), axis = -1)
  return loss

model = PyNet((512,512,3))
model.compile('adam', loss = loss_function)
model.summary()

"""###Data Augmentation"""

from google.colab import drive
import cv2 as cv
import matplotlib.pyplot as plt
drive.mount('/content/drive')

import zipfile

zipped_path = '/content/drive/MyDrive/Bokeh-dataset/Bokeh-dataset.zip'
extract_path = '/content/drive/MyDrive/Bokeh-dataset'

with zipfile.ZipFile(zipped_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

train_bokeh = '/content/drive/MyDrive/Bokeh-dataset/Bokeh-dataset/Training/bokeh'
train_org = '/content/drive/MyDrive/Bokeh-dataset/Bokeh-dataset/Training/original'
test_org = '/content/drive/MyDrive/Bokeh-dataset/Bokeh-dataset/Test/original'
test_bokeh = '/content/drive/MyDrive/Bokeh-dataset/Bokeh-dataset/Test/bokeh'

save_dir = '/content/drive/MyDrive/Bokeh-dataset/saved_models'

# x_train = np.zeros((4501, 1024, 1440, 3))
# #y_train = np.zeros()

# for i in range(4501):
#   x_train[i] = cv.imread(train_org + '/' + str(i) + '.jpg')[:,:1440,:]
#   #y_train.append(cv.imread(train_bokeh + '/' + str(i) + '.jpg')[:,:1440,:])

from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rotation_range=20,  
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.2,
    zoom_range=0.2, 
    horizontal_flip=True, 
    fill_mode='nearest' 
)

def trainModel(model, image_size, batch_size, training_set_size, epochs, start):
  l,b,h = image_size

  for i in range(training_set_size//batch_size):
    print('--------------batch ', i+1, '--------------')
    x_train = []
    y_train = []
    for j in range(batch_size):
      x_train.append(cv.resize(cv.imread(train_org + '/' + str(start + i*batch_size + j) + '.jpg'), (b//2, l//2))/255)
      y_train.append(cv.resize(cv.imread(train_bokeh + '/' + str(start + i*batch_size + j) + '.jpg'), (b, l))/255)
    model.fit(tf.convert_to_tensor(x_train), tf.convert_to_tensor(y_train), epochs = epochs)

"""###Train with first 500 image(augment = False, vgg = False)"""

image_size = (1024, 1024, 3)
batch_size = 1
training_set_size = 500
epochs = 10
start = 0
trainModel(model, image_size, batch_size, training_set_size, epochs, start)

model.save(save_dir + '/model_500')

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(1) + '.jpg'), (512, 512))/255)
y = model(tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
plt.imshow(y1)
y1.shape

t1 = cv.imread(train_bokeh + '/' + str(1) + '.jpg')
plt.imshow(t1)

np.mean((cv.resize(t1, (1500, 1024)) - y1)**2)







"""###Train till first 1000 images(augment = False, vgg = False)"""

model_saved_500 = tf.keras.models.load_model(save_dir + '/' + 'model_500', custom_objects = {'loss_function' : loss_function})

image_size = (1024, 1024, 3)
batch_size = 1
training_set_size = 500
epochs = 5
start = 500
trainModel(model_saved_500, image_size, batch_size, training_set_size, epochs, start)
model_saved_500.save(save_dir + '/' + 'model_1000')

x_train1 = []
x_train1.append(cv.resize(cv.imread(train_org + '/' + str(666) + '.jpg'), (512, 512))/255)
y02 = model_saved_500(tf.convert_to_tensor(x_train1)).numpy()

y2 = (cv.resize(y02.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
x2 = cv.resize(cv.imread(train_org + '/' + str(666) + '.jpg'), (1500, 1024))
plt.imshow(x2 + y2)
y2.shape

t = cv.imread(train_bokeh + '/' + str(666) + '.jpg')
#np.mean((cv.resize(t, (1500, 1024)) - y2)**2)
plt.imshow(t)

t1_gray = cv.cvtColor(t1, cv.COLOR_RGB2GRAY)
plt.imshow(t1_gray, cmap = 'gray')
#print(np.mean((cv.resize(t1, (1500, 1024)) - y1)**2))









"""###Training with first 500 images(augment = False, vgg = True)

Chainging loss function by including perceptual loss
"""

import tensorflow as tf
from tensorflow.keras.applications.vgg19 import VGG19
from tensorflow.keras.layers import Input
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.models import Model

class VGGPerceptualLoss(tf.keras.losses.Loss):
    def __init__(self, layers):
        super(VGGPerceptualLoss, self).__init__()
        self.layers = layers
        self.vgg = VGG19(weights='imagenet', include_top=False)
        self.criterion = MeanSquaredError()

    def call(self, y_true, y_pred):
        y_true_vgg = self.vgg(y_true)
        y_pred_vgg = self.vgg(y_pred)
        loss = 0
        for layer in self.layers:
            y_true_feat = y_true_vgg[layer]
            y_pred_feat = y_pred_vgg[layer]
            loss += 0.01 * self.criterion(y_true_feat, y_pred_feat)
            loss += loss_function(y_pred, y_true)
        return loss



# Example usage
vgg_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']  # Layers used for perceptual loss
vgg_loss = VGGPerceptualLoss(vgg_layers)
# input_image = tf.random.normal((1, 256, 256, 3))
# generated_image = tf.random.normal((1, 256, 256, 3))
# loss = vgg_loss(input_image, generated_image)

loss_function_vgg(input, )

image_size = (1024, 1024, 3)
batch_size = 1
training_set_size = 500
epochs = 5
start = 0
trainModel(model_vggLoss, image_size, batch_size, training_set_size, epochs, start)

model.save(save_dir + '/model_vggLoss_500')

y_vggLoss = model_vggLoss(tf.convert_to_tensor(x_train1)).numpy()
plt.imshow(y_vggLoss)

"""###Training till 1500 images(augment = False, vgg = false)"""

model_saved_1000 = tf.keras.models.load_model(save_dir + '/' + 'model_1000', custom_objects = {'loss_function' : loss_function})

image_size = (1024, 1024, 3)
batch_size = 1
training_set_size = 500
epochs = 5
start = 1000
trainModel(model_saved_1000, image_size, batch_size, training_set_size, epochs, start)
model_saved_1000.save(save_dir + '/' + 'model_1500')

y_1500 = model_saved_1000(tf.convert_to_tensor(x_train0)).numpy()
y_1500 = (cv.resize(y_1500.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
plt.imshow(y_1500)



"""###Sequential Training of the model with tf.session"""

def PyNet_seq(input_shape, instance_norm = True, instance_norm_level3 = False):

  with tf.compat.v1.variable_scope('generator'):

    #input = Input(input_shape)
    #with tf.compat.v1.variable_scope("generator"):

    space2depth_l0 = tf.nn.space_to_depth(input, 2)

    conv_l3_i1 = conv_multiple(space2depth_l0, 3, num_filters = 32, instance_norm = False)
    pool3 = maxpool(conv_l3_i1, 2)
    conv_l4_i1 = conv_multiple(pool3, 3, num_filters = 64, instance_norm = instance_norm)
    pool4 = maxpool(conv_l4_i1, 2)
    conv_l5_i1 = conv_multiple(pool4, 3, num_filters = 128, instance_norm = instance_norm)
    pool5 = maxpool(conv_l5_i1, 2)
    conv_l6_i1 = conv_multiple(pool5, 3, num_filters = 256, instance_norm = instance_norm)
    pool6 = maxpool(conv_l6_i1, 2)

    conv_l7_i1 = conv_multiple(pool6, 3, num_filters = 512, instance_norm = instance_norm)
    conv_l7_i2 = conv_multiple(conv_l7_i1, 3, num_filters = 512, instance_norm = instance_norm) + conv_l7_i1
    conv_l7_i3 = conv_multiple(conv_l7_i2, 3, num_filters = 512, instance_norm = instance_norm) + conv_l7_i2
    conv_l7_i4 = conv_multiple(conv_l7_i3, 3, num_filters = 512, instance_norm = instance_norm)

    conv_t6a = conv_transpose(conv_l7_i4, 256, 3, 2)      
    conv_t6b = conv_transpose(conv_l7_i4, 256, 3, 2)   

    conv_l7_out = conv_layer(conv_l7_i4, 3, 3, 1, relu=False, instance_norm=False)
    output_l7 = tf.nn.tanh(conv_l7_out) * 0.58 + 0.5

    #---------------------------------------------------------------------------------------------------------------------

    #conv_l6_i2 = tf.concat([conv_l6_i1, conv_t6a], 3)
    conv_l6_i2 = Concatenate()([conv_l6_i1, conv_t6a])
    conv_l6_i3 = conv_multiple(conv_l6_i2, 3, num_filters=256, instance_norm=instance_norm)
    conv_l6_i4 = conv_multiple(conv_l6_i3, 3, num_filters=256, instance_norm=instance_norm) + conv_l6_i3
    conv_l6_i5 = conv_multiple(conv_l6_i4, 3, num_filters=256, instance_norm=instance_norm) + conv_l6_i4
    #conv_l6_i6 = tf.concat([(conv_multiple(conv_l6_i5, 3, num_filters=256, instance_norm=instance_norm), conv_t6b)], 3)
    conv_l6_i6 = Concatenate()([conv_multiple(conv_l6_i5, 3, num_filters=256, instance_norm=instance_norm), conv_t6b])

    conv_l6_i7 = conv_multiple(conv_l6_i6, 3, num_filters=256, instance_norm=instance_norm)

    conv_t5a = conv_transpose(conv_l6_i7, 128, 3, 2)      
    conv_t5b = conv_transpose(conv_l6_i7, 128, 3, 2)      

    conv_l6_out = conv_layer(conv_l6_i7, 3, 3, 1, relu=False, instance_norm=False)
    output_l6 = tf.nn.tanh(conv_l6_out) * 0.58 + 0.5

    # -----------------------------------------------------------------------------------------------------------------------

    #conv_l5_i2 = tf.concat([conv_l5_i1, conv_t5a], 3)
    conv_l5_i2 = Concatenate()([conv_l5_i1, conv_t5a])
    conv_l5_i3 = conv_multiple(conv_l5_i2, 5, num_filters = 128, instance_norm = instance_norm) + conv_l5_i2
    conv_l5_i4 = conv_multiple(conv_l5_i3, 5, num_filters = 128, instance_norm = instance_norm) + conv_l5_i3
    conv_l5_i5 = conv_multiple(conv_l5_i4, 5, num_filters = 128, instance_norm = instance_norm) + conv_l5_i4
    #conv_l5_i6 = tf.concat([conv_multiple(conv_l5_i5, 5, num_filters = 128, instance_norm = instance_norm), conv_l5_i1], 3)
    conv_l5_i6 = Concatenate()([conv_multiple(conv_l5_i5, 5, num_filters = 128, instance_norm = instance_norm), conv_l5_i1])
    #conv_l5_i7 = tf.concat([conv_l5_i6, conv_t5b], 3)
    conv_l5_i7 = Concatenate()([conv_l5_i6, conv_t5b])

    conv_l5_i8 = conv_multiple(conv_l5_i7, 3, num_filters = 128, instance_norm = instance_norm)

    conv_t4a = conv_transpose(conv_l5_i8, 64, 3, 2)
    conv_t4b = conv_transpose(conv_l5_i8, 64, 3, 2)

    conv_l5_out = conv_layer(conv_l5_i8, 3, 3, 1, relu = False, instance_norm = False)
    output_l5 = tf.nn.tanh(conv_l5_out) * 0.58 + 0.5

    # ----------------------------------------------------------------------------------------------------------------------------------

    #conv_l4_i2 = tf.concat([conv_l4_i1, conv_t4a], 3)
    conv_l4_i2 = Concatenate()([conv_l4_i1, conv_t4a])
    #conv_l4_i3 = tf.concat([conv_multiple(conv_l4_i2, 5, num_filters = 64, instance_norm = instance_norm), conv_l4_i1], 3)
    conv_l4_i3 = Concatenate()([conv_multiple(conv_l4_i2, 5, num_filters = 64, instance_norm = instance_norm), conv_l4_i1])

    conv_l4_i4 = conv_multiple(conv_l4_i3, 7, num_filters = 64, instance_norm = instance_norm) + conv_l4_i3
    conv_l4_i5 = conv_multiple(conv_l4_i4, 7, num_filters = 64, instance_norm = instance_norm) + conv_l4_i4
    conv_l4_i6 = conv_multiple(conv_l4_i5, 7, num_filters = 64, instance_norm = instance_norm) + conv_l4_i5
    #conv_l4_i7 = tf.concat([conv_multiple(conv_l4_i6, 7, num_filters = 64, instance_norm = instance_norm), conv_l4_i1], 3)
    conv_l4_i7 = Concatenate()([conv_multiple(conv_l4_i6, 7, num_filters = 64, instance_norm = instance_norm), conv_l4_i1])

    #conv_l4_i8 = tf.concat([conv_multiple(conv_l4_i7, 5, num_filters = 64, instance_norm = instance_norm), conv_t4b], 3)
    conv_l4_i8 = Concatenate()([conv_multiple(conv_l4_i7, 5, num_filters = 64, instance_norm = instance_norm), conv_t4b])
    conv_l4_i9 = conv_multiple(conv_l4_i8, 3, num_filters = 64, instance_norm = instance_norm)

    conv_t3a = conv_transpose(conv_l4_i9, 32, 3, 2)
    conv_t3b = conv_transpose(conv_l4_i9, 32, 3, 2)

    conv_l4_out = conv_layer(conv_l4_i9, 3, 3, 1, relu = False, instance_norm = False)
    output_l4 = tf.nn.tanh(conv_l4_out) * 0.58 + 0.5    

    # ---------------------------------------------------------------------------------------------------------------------
    
    #conv_l3_i2 = tf.concat([conv_l3_i1, conv_t3a], 3)
    conv_l3_i2 = Concatenate()([conv_l3_i1, conv_t3a])
    #conv_l3_i3 = tf.concat([conv_multiple(conv_l3_i2, 5, num_filters = 32, instance_norm = False), conv_l3_i1], 3)
    conv_l3_i3 = Concatenate()([conv_multiple(conv_l3_i2, 5, num_filters = 32, instance_norm = False), conv_l3_i1])

    conv_l3_i4 = conv_multiple(conv_l3_i3, 7, num_filters = 32, instance_norm = False)
    conv_l3_i5 = conv_multiple(conv_l3_i4, 9, num_filters = 32, instance_norm = instance_norm_level3)
    conv_l3_i6 = conv_multiple(conv_l3_i5, 9, num_filters = 32, instance_norm = instance_norm_level3) + conv_l3_i5
    conv_l3_i7 = conv_multiple(conv_l3_i6, 9, num_filters = 32, instance_norm = instance_norm_level3) + conv_l3_i6
    conv_l3_i8 = conv_multiple(conv_l3_i7, 9, num_filters = 32, instance_norm = instance_norm_level3) + conv_l3_i7

    #conv_l3_i9 = tf.concat([conv_multiple(conv_l3_i8, 7, num_filters = 32, instance_norm = False), conv_l3_i1], 3)
    conv_l3_i9 = Concatenate()([conv_multiple(conv_l3_i8, 7, num_filters = 32, instance_norm = False), conv_l3_i1])
    #conv_l3_i10 = tf.concat([conv_multiple(conv_l3_i9, 5, num_filters = 32, instance_norm = False), conv_t3b], 3)
    conv_l3_i10 = Concatenate()([conv_multiple(conv_l3_i9, 5, num_filters = 32, instance_norm = False), conv_t3b])
    #conv_l3_i11 = tf.concat([conv_l3_i10, conv_l3_i1], 3)
    conv_l3_i11 = Concatenate()([conv_l3_i10, conv_l3_i1])
    conv_l3_i12 = conv_multiple(conv_l3_i11, 3, num_filters = 32, instance_norm = False)

    conv_l3_out = conv_layer(conv_l3_i12, 3, 3, 1, relu = False, instance_norm = False)
    output_l3 = tf.nn.tanh(conv_l3_out) * 0.58 + 0.5 

    # --------------------------------------------------------------------------------------------------------------
    
    conv_l2 = conv_transpose(conv_l3_i12, 8, 3, 2)
    conv_l2_out = conv_layer(conv_l2, 3, 3, 1, relu = False, instance_norm = False)
    output_l2 = tf.nn.tanh(conv_l2_out) * 0.58 + 0.5

    conv_l1 = conv_transpose(conv_l2_out, 3, 3, 2)
    conv_l1_out = conv_layer(conv_l1, 3, 3, 1, relu = False, instance_norm = False)

    output_l1 = tf.nn.tanh(conv_l1_out) * 0.58 + 0.5
    # outputs = [output_l1, output_l2, output_l3, output_l4, output_l5, output_l6, output_l7]
    # model = Model(input, output_l1)
    #return output_l1, output_l2, output_l3, output_l4, output_l5, output_l6, output_l7
  # return model
  return output_l1, output_l2, output_l3, output_l4, output_l5, output_l6, output_l7

batch_size = 1
train_size = 50
learning_rate = 1e-4
num_epochs = 5
start = 0



tf.compat.v1.disable_v2_behavior()
# scale = 2**(LEVEL - 2)

# width = int(512/scale)
# height = int(512/scale)
# depth = 3

LEVELS = [7, 6, 5, 4, 3]
np.random.seed(0)

# input = tf.compat.v1.placeholder(tf.float32, [batch_size, height, width, 4])       #placeholder is an alias for a varible that will be initialized later
# target = tf.compat.v1.placeholder(tf.float32, [batch_size, height, width, depth])  #placeholders enable building graph without explicitly specifing the variables

# output_l1, output_l2, output_l3, output_l4, output_l5, output_l6, output_l7 = PyNet_seq(input)

# loss_ssim = tf.reduce_mean(tf.image.ssim(bokeh_img, target, max_val = 1.0))
# loss_l1 = tf.compat.v1.losses.absolute_difference(bokeh_img, target)

with tf.Graph().as_default(), tf.compat.v1.Session() as sess: #initializing a tensorflow session
  # input = tf.compat.v1.placeholder(tf.float32, [batch_size, height, width, 4])       #placeholder is an alias for a varible that will be initialized later
  # target = tf.compat.v1.placeholder(tf.float32, [batch_size, height, width, depth])  #placeholders enable building graph without explicitly specifing the variables

  # output_l1, output_l2, output_l3, output_l4, output_l5, output_l6, output_l7 = PyNet_seq(input)

  # match LEVEL:
  #   case 7:
  #     bokeh_img = output_l7
  #   case 6:
  #     bokeh_img = output_l6
  #   case 5:
  #     bokeh_img = output_l5
  #   case 4:
  #     bokeh_img = output_l4
  #   case 3:
  #     bokeh_img = output_l3
  #   case 2:
  #     bokeh_img = output_l2
  #   case 1:
  #     bokeh_img = output_l1

  # bokeh_img_flattened = tf.reshape(bokeh_img, [-1, height * width * depth]) 
  # target_flat = tf.reshape(target, [-1, height * width * depth])

  # loss_ssim = tf.reduce_mean(tf.image.ssim(bokeh_img, target, max_val = 1.0))
  # loss_l1 = tf.compat.v1.losses.absolute_difference(bokeh_img, target)

  # if LEVEL < 1:
  #   loss_function_seq = loss_l1 * 100
  # else:
  #   loss_function_seq = loss_l1 * 100 + (1 - loss_ssim) * 100 #I have not used vgg loss yet

  # generator_vars = [v for v in tf.compat.v1.global_variables() if v.name.startswith('generator')]
  # train_step_gen = tf.compat.v1.train.AdamOptimizer(learning_rate).minimize(loss_function)

  # sess.run(tf.compat.v1.global_variables_initializer())

  # saver = tf.compat.v1.train.Saver(var_list = generator_vars, max_to_keep = 100)

  # if LEVEL < 7:
  #   saver.restore(sess, " ")
  
  # saver = tf.compat.v1.train.Saver(var_list = generator_vars, max_to_keep = 100)

  # generator_vars = [v for v in tf.compat.v1.global_variables() if v.name.startswith('generator')]
  # train_step_gen = tf.compat.v1.train.AdamOptimizer(learning_rate).minimize(loss_function)

  # sess.run(tf.compat.v1.global_variables_initializer())
  # saver = tf.compat.v1.train.Saver(var_list = generator_vars, max_to_keep = 100)

  for LEVEL in LEVELS:

    scale = 2**(LEVEL - 2)

    input_size = 1024
    width = int(input_size/scale)
    height = int(input_size/scale)
    depth = 3

    input = tf.compat.v1.placeholder(tf.float32, [batch_size, input_size, input_size, depth])       #placeholder is an alias for a varible that will be initialized later
    target = tf.compat.v1.placeholder(tf.float32, [batch_size, height, width, depth])  #placeholders enable building graph without explicitly specifing the variables

    output_l1, output_l2, output_l3, output_l4, output_l5, output_l6, output_l7 = PyNet_seq(input)

    if LEVEL==7:
      bokeh_img = output_l7
    elif LEVEL==6:
      bokeh_img = output_l6
    elif LEVEL==5:
      bokeh_img = output_l5
    elif LEVEL==4:
      bokeh_img = output_l4
    elif LEVEL==3:
      bokeh_img = output_l3
    elif LEVEL==2:
      bokeh_img = output_l2
    elif LEVEL==1:
      bokeh_img = output_l1

    loss_ssim = tf.reduce_mean(tf.image.ssim(bokeh_img, target, max_val = 1.0))
    loss_l1 = tf.compat.v1.losses.absolute_difference(bokeh_img, target)

    if LEVEL > 1:
      loss_function_seq = loss_l1
    else:
      loss_function_seq = loss_l1 + (1 - loss_ssim)
    generator_vars = [v for v in tf.compat.v1.global_variables() if v.name.startswith('generator')]
    train_step_gen = tf.compat.v1.train.AdamOptimizer(learning_rate).minimize(loss_function_seq)

    sess.run(tf.compat.v1.global_variables_initializer())
    saver = tf.compat.v1.train.Saver(var_list = generator_vars, max_to_keep = 100)
  

    if LEVEL < 7:
        print("Restoring Variables")
        saver.restore(sess, "/content/drive/MyDrive/Bokeh-dataset/Bokeh-dataset/models/pynet_level_" + str(LEVEL + 1) + ".ckpt")
    saver = tf.compat.v1.train.Saver(var_list = generator_vars, max_to_keep = 100)

    training_loss = 0.0
    print('Trainging level ' + str(LEVEL))
    for i in range(train_size//batch_size):
      print('batch ', i+1)
      x_train = []
      y_train = []
      for j in range(batch_size):
        x_train.append(cv.resize(cv.imread(train_org + '/' + str(start + i*batch_size + j) + '.jpg'), (input_size, input_size)))
        y_train.append(cv.resize(cv.imread(train_bokeh + '/' + str(start + i*batch_size + j) + '.jpg'), (width, height)))
      
      [loss_temp, temp] = sess.run([loss_function_seq, train_step_gen], feed_dict = {input: x_train, target: y_train})
      training_loss += loss_temp
      print(loss_temp)
    saver.save(sess, '/content/drive/MyDrive/Bokeh-dataset/Bokeh-dataset/models/pynet_level_' + str(LEVEL) + '.ckpt', write_meta_graph = False)





"""###Sequential Training"""

def PyNet_seq2(input_shape, instance_norm = True, instance_norm_level3 = False):
  input = Input(input_shape)
  #with tf.compat.v1.variable_scope("generator"):

  space2depth_l0 = tf.nn.space_to_depth(input, 2)

  conv_l3_i1 = conv_multiple(space2depth_l0, 3, num_filters = 32, instance_norm = False)
  pool3 = maxpool(conv_l3_i1, 2)
  conv_l4_i1 = conv_multiple(pool3, 3, num_filters = 64, instance_norm = instance_norm)
  pool4 = maxpool(conv_l4_i1, 2)
  conv_l5_i1 = conv_multiple(pool4, 3, num_filters = 128, instance_norm = instance_norm)
  pool5 = maxpool(conv_l5_i1, 2)
  conv_l6_i1 = conv_multiple(pool5, 3, num_filters = 256, instance_norm = instance_norm)
  pool6 = maxpool(conv_l6_i1, 2)

  conv_l7_i1 = conv_multiple(pool6, 3, num_filters = 512, instance_norm = instance_norm)
  conv_l7_i2 = conv_multiple(conv_l7_i1, 3, num_filters = 512, instance_norm = instance_norm) + conv_l7_i1
  conv_l7_i3 = conv_multiple(conv_l7_i2, 3, num_filters = 512, instance_norm = instance_norm) + conv_l7_i2
  conv_l7_i4 = conv_multiple(conv_l7_i3, 3, num_filters = 512, instance_norm = instance_norm)

  conv_t6a = conv_transpose(conv_l7_i4, 256, 3, 2)      
  conv_t6b = conv_transpose(conv_l7_i4, 256, 3, 2)   

  conv_l7_out = conv_layer(conv_l7_i4, 3, 3, 1, relu=False, instance_norm=False)
  output_l7 = tf.nn.tanh(conv_l7_out) * 0.58 + 0.5

  #---------------------------------------------------------------------------------------------------------------------

  #conv_l6_i2 = tf.concat([conv_l6_i1, conv_t6a], 3)
  conv_l6_i2 = Concatenate()([conv_l6_i1, conv_t6a])
  conv_l6_i3 = conv_multiple(conv_l6_i2, 3, num_filters=256, instance_norm=instance_norm)
  conv_l6_i4 = conv_multiple(conv_l6_i3, 3, num_filters=256, instance_norm=instance_norm) + conv_l6_i3
  conv_l6_i5 = conv_multiple(conv_l6_i4, 3, num_filters=256, instance_norm=instance_norm) + conv_l6_i4
  #conv_l6_i6 = tf.concat([(conv_multiple(conv_l6_i5, 3, num_filters=256, instance_norm=instance_norm), conv_t6b)], 3)
  conv_l6_i6 = Concatenate()([conv_multiple(conv_l6_i5, 3, num_filters=256, instance_norm=instance_norm), conv_t6b])

  conv_l6_i7 = conv_multiple(conv_l6_i6, 3, num_filters=256, instance_norm=instance_norm)

  conv_t5a = conv_transpose(conv_l6_i7, 128, 3, 2)      
  conv_t5b = conv_transpose(conv_l6_i7, 128, 3, 2)      

  conv_l6_out = conv_layer(conv_l6_i7, 3, 3, 1, relu=False, instance_norm=False)
  output_l6 = tf.nn.tanh(conv_l6_out) * 0.58 + 0.5

  # -----------------------------------------------------------------------------------------------------------------------

  #conv_l5_i2 = tf.concat([conv_l5_i1, conv_t5a], 3)
  conv_l5_i2 = Concatenate()([conv_l5_i1, conv_t5a])
  conv_l5_i3 = conv_multiple(conv_l5_i2, 5, num_filters = 128, instance_norm = instance_norm) + conv_l5_i2
  conv_l5_i4 = conv_multiple(conv_l5_i3, 5, num_filters = 128, instance_norm = instance_norm) + conv_l5_i3
  conv_l5_i5 = conv_multiple(conv_l5_i4, 5, num_filters = 128, instance_norm = instance_norm) + conv_l5_i4
  #conv_l5_i6 = tf.concat([conv_multiple(conv_l5_i5, 5, num_filters = 128, instance_norm = instance_norm), conv_l5_i1], 3)
  conv_l5_i6 = Concatenate()([conv_multiple(conv_l5_i5, 5, num_filters = 128, instance_norm = instance_norm), conv_l5_i1])
  #conv_l5_i7 = tf.concat([conv_l5_i6, conv_t5b], 3)
  conv_l5_i7 = Concatenate()([conv_l5_i6, conv_t5b])

  conv_l5_i8 = conv_multiple(conv_l5_i7, 3, num_filters = 128, instance_norm = instance_norm)

  conv_t4a = conv_transpose(conv_l5_i8, 64, 3, 2)
  conv_t4b = conv_transpose(conv_l5_i8, 64, 3, 2)

  conv_l5_out = conv_layer(conv_l5_i8, 3, 3, 1, relu = False, instance_norm = False)
  output_l5 = tf.nn.tanh(conv_l5_out) * 0.58 + 0.5

  # ----------------------------------------------------------------------------------------------------------------------------------

  #conv_l4_i2 = tf.concat([conv_l4_i1, conv_t4a], 3)
  conv_l4_i2 = Concatenate()([conv_l4_i1, conv_t4a])
  #conv_l4_i3 = tf.concat([conv_multiple(conv_l4_i2, 5, num_filters = 64, instance_norm = instance_norm), conv_l4_i1], 3)
  conv_l4_i3 = Concatenate()([conv_multiple(conv_l4_i2, 5, num_filters = 64, instance_norm = instance_norm), conv_l4_i1])

  conv_l4_i4 = conv_multiple(conv_l4_i3, 7, num_filters = 64, instance_norm = instance_norm) + conv_l4_i3
  conv_l4_i5 = conv_multiple(conv_l4_i4, 7, num_filters = 64, instance_norm = instance_norm) + conv_l4_i4
  conv_l4_i6 = conv_multiple(conv_l4_i5, 7, num_filters = 64, instance_norm = instance_norm) + conv_l4_i5
  #conv_l4_i7 = tf.concat([conv_multiple(conv_l4_i6, 7, num_filters = 64, instance_norm = instance_norm), conv_l4_i1], 3)
  conv_l4_i7 = Concatenate()([conv_multiple(conv_l4_i6, 7, num_filters = 64, instance_norm = instance_norm), conv_l4_i1])

  #conv_l4_i8 = tf.concat([conv_multiple(conv_l4_i7, 5, num_filters = 64, instance_norm = instance_norm), conv_t4b], 3)
  conv_l4_i8 = Concatenate()([conv_multiple(conv_l4_i7, 5, num_filters = 64, instance_norm = instance_norm), conv_t4b])
  conv_l4_i9 = conv_multiple(conv_l4_i8, 3, num_filters = 64, instance_norm = instance_norm)

  conv_t3a = conv_transpose(conv_l4_i9, 32, 3, 2)
  conv_t3b = conv_transpose(conv_l4_i9, 32, 3, 2)

  conv_l4_out = conv_layer(conv_l4_i9, 3, 3, 1, relu = False, instance_norm = False)
  output_l4 = tf.nn.tanh(conv_l4_out) * 0.58 + 0.5    

  # ---------------------------------------------------------------------------------------------------------------------
  
  #conv_l3_i2 = tf.concat([conv_l3_i1, conv_t3a], 3)
  conv_l3_i2 = Concatenate()([conv_l3_i1, conv_t3a])
  #conv_l3_i3 = tf.concat([conv_multiple(conv_l3_i2, 5, num_filters = 32, instance_norm = False), conv_l3_i1], 3)
  conv_l3_i3 = Concatenate()([conv_multiple(conv_l3_i2, 5, num_filters = 32, instance_norm = False), conv_l3_i1])

  conv_l3_i4 = conv_multiple(conv_l3_i3, 7, num_filters = 32, instance_norm = False)
  conv_l3_i5 = conv_multiple(conv_l3_i4, 9, num_filters = 32, instance_norm = instance_norm_level3)
  conv_l3_i6 = conv_multiple(conv_l3_i5, 9, num_filters = 32, instance_norm = instance_norm_level3) + conv_l3_i5
  conv_l3_i7 = conv_multiple(conv_l3_i6, 9, num_filters = 32, instance_norm = instance_norm_level3) + conv_l3_i6
  conv_l3_i8 = conv_multiple(conv_l3_i7, 9, num_filters = 32, instance_norm = instance_norm_level3) + conv_l3_i7

  #conv_l3_i9 = tf.concat([conv_multiple(conv_l3_i8, 7, num_filters = 32, instance_norm = False), conv_l3_i1], 3)
  conv_l3_i9 = Concatenate()([conv_multiple(conv_l3_i8, 7, num_filters = 32, instance_norm = False), conv_l3_i1])
  #conv_l3_i10 = tf.concat([conv_multiple(conv_l3_i9, 5, num_filters = 32, instance_norm = False), conv_t3b], 3)
  conv_l3_i10 = Concatenate()([conv_multiple(conv_l3_i9, 5, num_filters = 32, instance_norm = False), conv_t3b])
  #conv_l3_i11 = tf.concat([conv_l3_i10, conv_l3_i1], 3)
  conv_l3_i11 = Concatenate()([conv_l3_i10, conv_l3_i1])
  conv_l3_i12 = conv_multiple(conv_l3_i11, 3, num_filters = 32, instance_norm = False)

  conv_l3_out = conv_layer(conv_l3_i12, 3, 3, 1, relu = False, instance_norm = False)
  output_l3 = tf.nn.tanh(conv_l3_out) * 0.58 + 0.5 

  # --------------------------------------------------------------------------------------------------------------
  
  conv_l2 = conv_transpose(conv_l3_i12, 8, 3, 2)
  conv_l2_out = conv_layer(conv_l2, 3, 3, 1, relu = False, instance_norm = False)
  output_l2 = tf.nn.tanh(conv_l2_out) * 0.58 + 0.5

  conv_l1 = conv_transpose(conv_l2_out, 3, 3, 2)
  conv_l1_out = conv_layer(conv_l1, 3, 3, 1, relu = False, instance_norm = False)

  output_l1 = tf.nn.tanh(conv_l1_out) * 0.58 + 0.5
  outputs = [output_l1, output_l2, output_l3, output_l4, output_l5, output_l6, output_l7]
  model = [model7, model6, model5, model4, model3, model2, model1] = [Model(input, output_l7), Model(input, output_l6), Model(input, output_l5), Model(input, output_l4), Model(input, output_l3), Model(input, output_l2), Model(input, output_l1)]
  #return output_l1, output_l2, output_l3, output_l4, output_l5, output_l6, output_l7
  return model

loss1 = tf.keras.losses.MeanAbsoluteError()
def loss2(out_img, target):
  return tf.math.reduce_mean(tf.math.abs(out_img - target), axis = -1) + tf.math.reduce_mean(tf.image.ssim(bokeh_img, target, max_val = 1.0))

import cv2 as cv
def trainModel_seq(modelA, image_size, batch_size, train_set_size, epochs, start, LEVEL):
  l,b,h = image_size

  for i in range(train_set_size//batch_size):
    print('--------------batch ', i+1, '--------------')
    x_train = []
    y_train = []
    for j in range(batch_size):
      x_train.append(cv.resize(cv.imread(train_org + '/' + str(start + i*batch_size + j) + '.jpg'), (b//2, l//2))/255)
      y_train.append(cv.resize(cv.imread(train_bokeh + '/' + str(start + i*batch_size + j) + '.jpg'), (int(b/(2**(LEVEL-1))), int(b/(2**(LEVEL-1))) ))/255)
    modelA.fit(tf.convert_to_tensor(x_train), tf.convert_to_tensor(y_train), epochs = epochs)

image_size = (1024, 1024, 3)
batch_size = 1
train_set_size = 100
start = 0
epochs = 10
[model7, model6, model5, model4, model3, model2, model1] = PyNet_seq2((512, 512, 3))

LEVEL = 7
model7.compile('adam', loss = loss_function)
trainModel_seq(model7, image_size, batch_size, train_set_size, epochs, start, LEVEL)
level7_weights = model7.get_weights()

model7.save(save_dir + '/model7')

LEVEL = 6
model6.weights[0:len(level7_weights)] = level7_weights
model6.compile('adam', loss = loss_function)
trainModel_seq(model6, image_size, batch_size, train_set_size, epochs, start, LEVEL)
level6_weights = model6.get_weights()

model6.save(save_dir + '/model6')

LEVEL = 5
model5.weights[0:len(level6_weights)] = level6_weights
model5.compile('adam', loss = loss_function)
trainModel_seq(model5, image_size, batch_size, train_set_size, epochs, start, LEVEL)
level5_weights = model5.get_weights()

model5.save(save_dir + '/model5')

LEVEL = 4
model4.weights[0:len(level5_weights)] = level5_weights
model4.compile('adam', loss = loss_function)
trainModel_seq(model4, image_size, batch_size, train_set_size, epochs, start, LEVEL)
level4_weights = model4.get_weights()

model4.save(save_dir + '/model4')

LEVEL = 3
model3.weights[0:len(level4_weights)] = level4_weights
model3.compile('adam', loss = loss_function)
trainModel_seq(model3, image_size, batch_size, train_set_size, epochs, start, LEVEL)
level3_weights = model3.get_weights()

model3.save(save_dir + '/model3')

LEVEL = 2
model2.weights[0:len(level3_weights)] = level3_weights
model2.compile('adam', loss = loss_function)
trainModel_seq(model2, image_size, batch_size, train_set_size, epochs, start, LEVEL)
level2_weights = model2.get_weights()

model2.save(save_dir + '/model2')

# model2_saved = tf.keras.models.load_model(save_dir + '/' + 'model2', custom_objects = {'loss_function' : loss_function})
# level2_weights = model2_saved.weights

LEVEL = 1
model1.weights[0:len(level2_weights)] = level2_weights
model1.compile('adam', loss = loss1)
trainModel_seq(model1, image_size, batch_size, train_set_size, epochs, start, LEVEL)
level1_weights = model1.get_weights()

model1.save(save_dir + '/model1')

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(1) + '.jpg'), (512, 512))/255)
y = model1(tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
plt.imshow(y1)
y1.shape

t1 = cv.imread(train_bokeh + '/' + str(1) + '.jpg')
plt.imshow(t1)

np.mean((cv.resize(t1, (1500, 1024)) - y1)**2)



"""###25 train images"""

def trainModelSequrntially(Model, image_size, batch_size, train_set_size, start, epochs):
  [model7, model6, model5, model4, model3, model2, model1] = Model
  #-------------------training layer 7----------------------------#
  print('##-----Training Layer 7 -----##')
  model7.compile('adam', loss = loss_function)
  trainModel_seq(model7, image_size, batch_size, train_set_size, epochs, start, 7)
  level7_weights = model7.get_weights()
  model7.save(save_dir + str(train_set_size) + ' training images ' + '/model7')

  #-------------------training layer 6----------------------------#
  print('##-----Training Layer 6 -----##')
  model6.weights[0:len(level7_weights)] = level7_weights
  model6.compile('adam', loss = loss_function)
  trainModel_seq(model6, image_size, batch_size, train_set_size, epochs, start, 6)
  level6_weights = model6.get_weights()
  model6.save(save_dir + str(train_set_size) + ' training images ' + '/model6')

  #-------------------training layer 5----------------------------#
  print('##-----Training Layer 5 -----##')
  model5.weights[0:len(level6_weights)] = level6_weights
  model5.compile('adam', loss = loss_function)
  trainModel_seq(model5, image_size, batch_size, train_set_size, epochs, start, 5)
  level5_weights = model5.get_weights()
  model5.save(save_dir + str(train_set_size) + ' training images ' + '/model5')

  #-------------------training layer 4----------------------------#
  print('##-----Training Layer 4 -----##')
  model4.weights[0:len(level5_weights)] = level5_weights
  model4.compile('adam', loss = loss_function)
  trainModel_seq(model4, image_size, batch_size, train_set_size, epochs, start, 4)
  level4_weights = model4.get_weights()
  model4.save(save_dir + str(train_set_size) + ' training images ' + '/model4')

  #-------------------training layer 3----------------------------#
  print('##-----Training Layer 3 -----##')
  model3.weights[0:len(level4_weights)] = level4_weights
  model3.compile('adam', loss = loss_function)
  trainModel_seq(model3, image_size, batch_size, train_set_size, epochs, start, 3)
  level3_weights = model3.get_weights()
  model3.save(save_dir + str(train_set_size) + ' training images ' + '/model3')

  #-------------------training layer 2----------------------------#
  print('##-----Training Layer 2 -----##')
  model2.weights[0:len(level3_weights)] = level3_weights
  model2.compile('adam', loss = loss_function)
  trainModel_seq(model2, image_size, batch_size, train_set_size, epochs, start, 2)
  level2_weights = model2.get_weights()
  model2.save(save_dir + str(train_set_size) + ' training images ' + '/model2')

  #-------------------training layer 1----------------------------#
  print('##-----Training Layer 1 -----##')
  model1.weights[0:len(level2_weights)] = level2_weights
  model1.compile('adam', loss = loss1)
  trainModel_seq(model1, image_size, batch_size, train_set_size, epochs, start, 1)
  level1_weights = model1.get_weights()
  model1.save(save_dir + str(train_set_size) + ' training images ' + '/model1')

image_size = ((1024, 1024, 3))
Model_25 = PyNet_seq2((512, 512, 3))
trainModelSequrntially(Model_25, image_size, batch_size = 1, train_set_size = 25, start = 0, epochs = 10)

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(1) + '.jpg'), (512, 512))/255)
y = Model_25[6](tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
plt.imshow(y1)
y1.shape

"""###200 Images"""

image_size = ((1024, 1024, 3))
Model_200 = PyNet_seq2((512, 512, 3))
trainModelSequrntially(Model_200, image_size, batch_size = 1, train_set_size = 200, start = 0, epochs = 10)

Model_200 = PyNet_seq2((512, 512, 3))
model_200_level2 = tf.keras.models.load_model('/content/drive/MyDrive/Bokeh-dataset/saved_models/model2', custom_objects = {'loss_function' : loss_function})

model1 = Model_200[6]
model_200_level2_weights = model_200_level2.get_weights()
model1.weights[0:len(model_200_level2_weights)] = model_200_level2_weights
model1.compile('adam', loss = loss1)
trainModel_seq(model1, image_size = (1024, 1024, 1024), batch_size = 1, train_set_size = 200, epochs = 10, start = 0, LEVEL = 1)
level1_weights = model1.get_weights()
model1.save(save_dir + str(train_set_size) + ' training images ' + '/model1')

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(1) + '.jpg'), (512, 512))/255)
y = Model_200[6](tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
t1 = cv.imread(train_bokeh + '/' + str(1) + '.jpg')
plt.subplot(121)
plt.imshow(y1)
plt.title('output')
plt.subplot(122)
plt.imshow(t1)
plt.title('target')

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(26) + '.jpg'), (512, 512))/255)
y = Model_200[6](tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
t1 = cv.imread(train_bokeh + '/' + str(26) + '.jpg')
plt.subplot(121)
plt.imshow(y1)
plt.title('output')
plt.subplot(122)
plt.imshow(t1)
plt.title('target')

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(99) + '.jpg'), (512, 512))/255)
y = Model_200[6](tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
t1 = cv.imread(train_bokeh + '/' + str(99) + '.jpg')
plt.subplot(121)
plt.imshow(y1)
plt.title('output')
plt.subplot(122)
plt.imshow(t1)
plt.title('target')

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(104) + '.jpg'), (512, 512))/255)
y = Model_200[6](tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
t1 = cv.imread(train_bokeh + '/' + str(104) + '.jpg')
plt.subplot(121)
plt.imshow(y1)
plt.title('output')
plt.subplot(122)
plt.imshow(t1)
plt.title('target')

"""###Modifying the baseline PyNet achitecture"""

def PyNet_seq_reduced(input_shape, instance_norm = True, instance_norm_level3 = False):
  input = Input(input_shape)
  #with tf.compat.v1.variable_scope("generator"):

  space2depth_l0 = tf.nn.space_to_depth(input, 2)

  conv_l3_i1 = conv_multiple(space2depth_l0, 3, num_filters = 32, instance_norm = False)
  pool3 = maxpool(conv_l3_i1, 2)
  conv_l4_i1 = conv_multiple(pool3, 3, num_filters = 64, instance_norm = instance_norm)
  pool4 = maxpool(conv_l4_i1, 2)
  conv_l5_i1 = conv_multiple(pool4, 3, num_filters = 128, instance_norm = instance_norm)
  pool5 = maxpool(conv_l5_i1, 2)
  conv_l6_i1 = conv_multiple(pool5, 3, num_filters = 256, instance_norm = instance_norm)
  pool6 = maxpool(conv_l6_i1, 2)

  conv_l7_i1 = conv_multiple(pool6, 3, num_filters = 512, instance_norm = instance_norm)
  conv_l7_i2 = conv_multiple(conv_l7_i1, 3, num_filters = 512, instance_norm = instance_norm) + conv_l7_i1
  conv_l7_i3 = conv_multiple(conv_l7_i2, 3, num_filters = 512, instance_norm = instance_norm) + conv_l7_i2
  conv_l7_i4 = conv_multiple(conv_l7_i3, 3, num_filters = 512, instance_norm = instance_norm)

  conv_t6a = conv_transpose(conv_l7_i4, 256, 3, 2)      
  conv_t6b = conv_transpose(conv_l7_i4, 256, 3, 2)   

  conv_l7_out = conv_layer(conv_l7_i4, 3, 3, 1, relu=False, instance_norm=False)
  output_l7 = tf.nn.tanh(conv_l7_out) * 0.58 + 0.5

  #---------------------------------------------------------------------------------------------------------------------

  #conv_l6_i2 = tf.concat([conv_l6_i1, conv_t6a], 3)
  conv_l6_i2 = Concatenate()([conv_l6_i1, conv_t6a])
  conv_l6_i3 = conv_multiple(conv_l6_i2, 3, num_filters=256, instance_norm=instance_norm)
  conv_l6_i4 = conv_multiple(conv_l6_i3, 3, num_filters=256, instance_norm=instance_norm) + conv_l6_i3
  conv_l6_i5 = conv_multiple(conv_l6_i4, 3, num_filters=256, instance_norm=instance_norm) + conv_l6_i4
  #conv_l6_i6 = tf.concat([(conv_multiple(conv_l6_i5, 3, num_filters=256, instance_norm=instance_norm), conv_t6b)], 3)
  conv_l6_i6 = Concatenate()([conv_multiple(conv_l6_i5, 3, num_filters=256, instance_norm=instance_norm), conv_t6b])

  conv_l6_i7 = conv_multiple(conv_l6_i6, 3, num_filters=256, instance_norm=instance_norm)

  conv_t5a = conv_transpose(conv_l6_i7, 128, 3, 2)      
  conv_t5b = conv_transpose(conv_l6_i7, 128, 3, 2)      

  conv_l6_out = conv_layer(conv_l6_i7, 3, 3, 1, relu=False, instance_norm=False)
  output_l6 = tf.nn.tanh(conv_l6_out) * 0.58 + 0.5

  # -----------------------------------------------------------------------------------------------------------------------

  #conv_l5_i2 = tf.concat([conv_l5_i1, conv_t5a], 3)
  conv_l5_i2 = Concatenate()([conv_l5_i1, conv_t5a])
  conv_l5_i3 = conv_multiple(conv_l5_i2, 5, num_filters = 128, instance_norm = instance_norm) + conv_l5_i2
  conv_l5_i4 = conv_multiple(conv_l5_i3, 5, num_filters = 128, instance_norm = instance_norm) + conv_l5_i3
  conv_l5_i5 = conv_multiple(conv_l5_i4, 5, num_filters = 128, instance_norm = instance_norm) + conv_l5_i4
  #conv_l5_i6 = tf.concat([conv_multiple(conv_l5_i5, 5, num_filters = 128, instance_norm = instance_norm), conv_l5_i1], 3)
  conv_l5_i6 = Concatenate()([conv_multiple(conv_l5_i5, 5, num_filters = 128, instance_norm = instance_norm), conv_l5_i1])
  #conv_l5_i7 = tf.concat([conv_l5_i6, conv_t5b], 3)
  conv_l5_i7 = Concatenate()([conv_l5_i6, conv_t5b])

  conv_l5_i8 = conv_multiple(conv_l5_i7, 3, num_filters = 128, instance_norm = instance_norm)

  conv_t4a = conv_transpose(conv_l5_i8, 64, 3, 2)
  conv_t4b = conv_transpose(conv_l5_i8, 64, 3, 2)

  conv_l5_out = conv_layer(conv_l5_i8, 3, 3, 1, relu = False, instance_norm = False)
  output_l5 = tf.nn.tanh(conv_l5_out) * 0.58 + 0.5

  # ----------------------------------------------------------------------------------------------------------------------------------

  #conv_l4_i2 = tf.concat([conv_l4_i1, conv_t4a], 3)
  conv_l4_i2 = Concatenate()([conv_l4_i1, conv_t4a])
  #conv_l4_i3 = tf.concat([conv_multiple(conv_l4_i2, 5, num_filters = 64, instance_norm = instance_norm), conv_l4_i1], 3)
  conv_l4_i3 = Concatenate()([conv_multiple(conv_l4_i2, 5, num_filters = 64, instance_norm = instance_norm), conv_l4_i1])

  conv_l4_i4 = conv_multiple(conv_l4_i3, 7, num_filters = 64, instance_norm = instance_norm) + conv_l4_i3
  conv_l4_i5 = conv_multiple(conv_l4_i4, 7, num_filters = 64, instance_norm = instance_norm) + conv_l4_i4
  conv_l4_i6 = conv_multiple(conv_l4_i5, 7, num_filters = 64, instance_norm = instance_norm) + conv_l4_i5
  #conv_l4_i7 = tf.concat([conv_multiple(conv_l4_i6, 7, num_filters = 64, instance_norm = instance_norm), conv_l4_i1], 3)
  conv_l4_i7 = Concatenate()([conv_multiple(conv_l4_i6, 7, num_filters = 64, instance_norm = instance_norm), conv_l4_i1])

  #conv_l4_i8 = tf.concat([conv_multiple(conv_l4_i7, 5, num_filters = 64, instance_norm = instance_norm), conv_t4b], 3)
  conv_l4_i8 = Concatenate()([conv_multiple(conv_l4_i7, 5, num_filters = 64, instance_norm = instance_norm), conv_t4b])
  conv_l4_i9 = conv_multiple(conv_l4_i8, 3, num_filters = 64, instance_norm = instance_norm)

  conv_t3a = conv_transpose(conv_l4_i9, 32, 3, 2)
  conv_t3b = conv_transpose(conv_l4_i9, 32, 3, 2)

  conv_l4_out = conv_layer(conv_l4_i9, 3, 3, 1, relu = False, instance_norm = False)
  output_l4 = tf.nn.tanh(conv_l4_out) * 0.58 + 0.5    

  # ---------------------------------------------------------------------------------------------------------------------
  
  # ##conv_l3_i2 = tf.concat([conv_l3_i1, conv_t3a], 3)
  # conv_l3_i2 = Concatenate()([conv_l3_i1, conv_t3a])
  # ##conv_l3_i3 = tf.concat([conv_multiple(conv_l3_i2, 5, num_filters = 32, instance_norm = False), conv_l3_i1], 3)
  # conv_l3_i3 = Concatenate()([conv_multiple(conv_l3_i2, 5, num_filters = 32, instance_norm = False), conv_l3_i1])

  # conv_l3_i4 = conv_multiple(conv_l3_i3, 7, num_filters = 32, instance_norm = False)
  # conv_l3_i5 = conv_multiple(conv_l3_i4, 9, num_filters = 32, instance_norm = instance_norm_level3)
  # conv_l3_i6 = conv_multiple(conv_l3_i5, 9, num_filters = 32, instance_norm = instance_norm_level3) + conv_l3_i5
  # conv_l3_i7 = conv_multiple(conv_l3_i6, 9, num_filters = 32, instance_norm = instance_norm_level3) + conv_l3_i6
  # conv_l3_i8 = conv_multiple(conv_l3_i7, 9, num_filters = 32, instance_norm = instance_norm_level3) + conv_l3_i7

  # ##conv_l3_i9 = tf.concat([conv_multiple(conv_l3_i8, 7, num_filters = 32, instance_norm = False), conv_l3_i1], 3)
  # conv_l3_i9 = Concatenate()([conv_multiple(conv_l3_i8, 7, num_filters = 32, instance_norm = False), conv_l3_i1])
  # ##conv_l3_i10 = tf.concat([conv_multiple(conv_l3_i9, 5, num_filters = 32, instance_norm = False), conv_t3b], 3)
  # conv_l3_i10 = Concatenate()([conv_multiple(conv_l3_i9, 5, num_filters = 32, instance_norm = False), conv_t3b])
  # ##conv_l3_i11 = tf.concat([conv_l3_i10, conv_l3_i1], 3)
  # conv_l3_i11 = Concatenate()([conv_l3_i10, conv_l3_i1])
  # conv_l3_i12 = conv_multiple(conv_l3_i11, 3, num_filters = 32, instance_norm = False)

  # conv_l3_out = conv_layer(conv_l3_i12, 3, 3, 1, relu = False, instance_norm = False)
  # output_l3 = tf.nn.tanh(conv_l3_out) * 0.58 + 0.5 

  # --------------------------------------------------------------------------------------------------------------
  
  conv_l3 = conv_transpose(conv_l4_i9, 8, 3, 2)
  conv_l3_out = conv_layer(conv_l3, 3, 3, 1, relu = False, instance_norm = False)
  output_l3 = tf.nn.tanh(conv_l3_out) * 0.58 + 0.5


  conv_l2 = conv_transpose(conv_l3, 8, 3, 2)
  conv_l2_out = conv_layer(conv_l2, 3, 3, 1, relu = False, instance_norm = False)
  output_l2 = tf.nn.tanh(conv_l2_out) * 0.58 + 0.5

  conv_l1 = conv_transpose(conv_l2_out, 3, 3, 2)
  conv_l1_out = conv_layer(conv_l1, 3, 3, 1, relu = False, instance_norm = False)

  output_l1 = tf.nn.tanh(conv_l1_out) * 0.58 + 0.5
  outputs = [output_l1, output_l2, output_l3, output_l4, output_l5, output_l6, output_l7]
  model = [model7, model6, model5, model4, model3, model2, model1] = [Model(input, output_l7), Model(input, output_l6), Model(input, output_l5), Model(input, output_l4), Model(input, output_l3), Model(input, output_l2), Model(input, output_l1)]
  #return output_l1, output_l2, output_l3, output_l4, output_l5, output_l6, output_l7
  return model

def trainModelSequrntially_reduced(Model, image_size, batch_size, train_set_size, start, epochs):
  [model7, model6, model5, model4, model2, model1] = Model
  #-------------------training layer 7----------------------------#
  print('##-----Training Layer 7 -----##')
  model7.compile('adam', loss = loss_function)
  trainModel_seq(model7, image_size, batch_size, train_set_size, epochs, start, 7)
  level7_weights = model7.get_weights()
  model7.save(save_dir + 'reduced' + str(train_set_size) + '/model7')

  #-------------------training layer 6----------------------------#
  print('##-----Training Layer 6 -----##')
  model6.weights[0:len(level7_weights)] = level7_weights
  model6.compile('adam', loss = loss_function)
  trainModel_seq(model6, image_size, batch_size, train_set_size, epochs, start, 6)
  level6_weights = model6.get_weights()
  model6.save(save_dir + 'reduced' + str(train_set_size) + '/model6')

  #-------------------training layer 5----------------------------#
  print('##-----Training Layer 5 -----##')
  model5.weights[0:len(level6_weights)] = level6_weights
  model5.compile('adam', loss = loss_function)
  trainModel_seq(model5, image_size, batch_size, train_set_size, epochs, start, 5)
  level5_weights = model5.get_weights()
  model5.save(save_dir + 'reduced' + str(train_set_size) + '/model5')

  #-------------------training layer 4----------------------------#
  print('##-----Training Layer 4 -----##')
  model4.weights[0:len(level5_weights)] = level5_weights
  model4.compile('adam', loss = loss_function)
  trainModel_seq(model4, image_size, batch_size, train_set_size, epochs, start, 4)
  level4_weights = model4.get_weights()
  model4.save(save_dir + 'reduced' + str(train_set_size) + '/model4')

  #-------------------training layer 3----------------------------#
  # print('##-----Training Layer 3 -----##')
  # model3.weights[0:len(level4_weights)] = level4_weights
  # model3.compile('adam', loss = loss_function)
  # trainModel_seq(model3, image_size, batch_size, train_set_size, epochs, start, 3)
  # level3_weights = model3.get_weights()
  # model3.save(save_dir + str(train_set_size) + ' training images ' + '/model3')

  #-------------------training layer 2----------------------------#
  print('##-----Training Layer 2 -----##')
  model2.weights[0:len(level3_weights)] = level3_weights
  model2.compile('adam', loss = loss_function)
  trainModel_seq(model2, image_size, batch_size, train_set_size, epochs, start, 2)
  level2_weights = model2.get_weights()
  model2.save(save_dir + 'reduced' + str(train_set_size) + '/model2')

  #-------------------training layer 1----------------------------#
  print('##-----Training Layer 1 -----##')
  model1.weights[0:len(level2_weights)] = level2_weights
  model1.compile('adam', loss = loss1)
  trainModel_seq(model1, image_size, batch_size, train_set_size, epochs, start, 1)
  level1_weights = model1.get_weights()
  model1.save(save_dir + 'reduced' + str(train_set_size) + '/model1')

Model_reduced_25 = PyNet_seq_reduced((512, 512, 3))

trainModelSequrntially(Model_reduced_25, image_size=(1024, 1024, 3), batch_size = 1, train_set_size = 25, start = 0, epochs = 10)

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(1) + '.jpg'), (512, 512))/255)
y = Model_reduced_25[6](tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
t1 = cv.imread(train_bokeh + '/' + str(1) + '.jpg')
plt.subplot(121)
plt.imshow(y1)
plt.title('output')
plt.subplot(122)
plt.imshow(t1)
plt.title('target')

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(26) + '.jpg'), (512, 512))/255)
y = Model_reduced_25[6](tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
t1 = cv.imread(train_bokeh + '/' + str(26) + '.jpg')
plt.subplot(121)
plt.imshow(y1)
plt.title('output')
plt.subplot(122)
plt.imshow(t1)
plt.title('target')

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(99) + '.jpg'), (512, 512))/255)
y = Model_reduced_25[6](tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
t1 = cv.imread(train_bokeh + '/' + str(99) + '.jpg')
plt.subplot(121)
plt.imshow(y1)
plt.title('output')
plt.subplot(122)
plt.imshow(t1)
plt.title('target')

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(104) + '.jpg'), (512, 512))/255)
y = Model_reduced_25[6](tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
t1 = cv.imread(train_bokeh + '/' + str(104) + '.jpg')
plt.subplot(121)
plt.imshow(y1)
plt.title('output')
plt.subplot(122)
plt.imshow(t1)
plt.title('target')

"""###400 Images"""

image_size = ((1024, 1024, 3))
Model_400 = PyNet_seq2((512, 512, 3))
trainModelSequrntially(Model_400, image_size, batch_size = 1, train_set_size = 400, start = 0, epochs = 10)

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(1) + '.jpg'), (512, 512))/255)
Model_400_saved = tf.keras.models.load_model('/content/drive/MyDrive/Bokeh-dataset/saved_models400/model1', custom_objects = {'loss_function' : loss1})
y = Model_400_saved(tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
t1 = cv.imread(train_bokeh + '/' + str(1) + '.jpg')
#plt.figure(figsize=(10,5))
plt.subplot(121)
plt.imshow(y1)
plt.title('output')
plt.subplot(122)
plt.imshow(t1)
plt.title('target')

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(26) + '.jpg'), (512, 512))/255)
y = Model_400_saved(tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
t1 = cv.imread(train_bokeh + '/' + str(26) + '.jpg')
plt.subplot(121)
plt.imshow(y1)
plt.title('output')
plt.subplot(122)
plt.imshow(t1)
plt.title('target')

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(99) + '.jpg'), (512, 512))/255)
y = Model_400_saved(tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
t1 = cv.imread(train_bokeh + '/' + str(99) + '.jpg')
plt.subplot(121)
plt.imshow(y1)
plt.title('output')
plt.subplot(122)
plt.imshow(t1)
plt.title('target')

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(104) + '.jpg'), (512, 512))/255)
y = Model_400_saved(tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
t1 = cv.imread(train_bokeh + '/' + str(104) + '.jpg')
plt.subplot(121)
plt.imshow(y1)
plt.title('output')
plt.subplot(122)
plt.imshow(t1)
plt.title('target')

"""###800 Images"""

image_size = ((1024, 1024, 3))
# Model_l1_400_saved = tf.keras.models.load_model('/content/drive/MyDrive/Bokeh-dataset/saved_models400/model1', custom_objects = {'loss_function' : loss1})
# Model_l2_400_saved = tf.keras.models.load_model('/content/drive/MyDrive/Bokeh-dataset/saved_models400/model2', custom_objects = {'loss_function' : loss_function})
# Model_l3_400_saved = tf.keras.models.load_model('/content/drive/MyDrive/Bokeh-dataset/saved_models400/model3', custom_objects = {'loss_function' : loss_function})
# Model_l4_400_saved = tf.keras.models.load_model('/content/drive/MyDrive/Bokeh-dataset/saved_models400/model4', custom_objects = {'loss_function' : loss_function})
# Model_l5_400_saved = tf.keras.models.load_model('/content/drive/MyDrive/Bokeh-dataset/saved_models400/model5', custom_objects = {'loss_function' : loss_function})
# Model_l6_400_saved = tf.keras.models.load_model('/content/drive/MyDrive/Bokeh-dataset/saved_models400/model6', custom_objects = {'loss_function' : loss_function})
# Model_l7_400_saved = tf.keras.models.load_model('/content/drive/MyDrive/Bokeh-dataset/saved_models400/model7', custom_objects = {'loss_function' : loss_function})

#odel_800 = [Model_l7_400_saved, Model_l6_400_saved, Model_l5_400_saved, Model_l4_400_saved, Model_l3_400_saved, Model_l2_400_saved, Model_l1_400_saved]
Model_800 = PyNet_seq2((512, 512, 3))
trainModelSequrntially(Model_800, image_size, batch_size = 1, train_set_size = 800, start = 0, epochs = 10)

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(1) + '.jpg'), (512, 512))/255)
y = Model_800[6](tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
t1 = cv.imread(train_bokeh + '/' + str(1) + '.jpg')
plt.subplot(121)
plt.imshow(y1)
plt.title('output')
plt.subplot(122)
plt.imshow(t1)
plt.title('target')

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(26) + '.jpg'), (512, 512))/255)
y = Model_800[6](tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
t1 = cv.imread(train_bokeh + '/' + str(26) + '.jpg')
plt.subplot(121)
plt.imshow(y1)
plt.title('output')
plt.subplot(122)
plt.imshow(t1)
plt.title('target')

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(99) + '.jpg'), (512, 512))/255)
y = Model_800[6](tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
t1 = cv.imread(train_bokeh + '/' + str(99) + '.jpg')
plt.subplot(121)
plt.imshow(y1)
plt.title('output')
plt.subplot(122)
plt.imshow(t1)
plt.title('target')

x_train0 = []
x_train0.append(cv.resize(cv.imread(train_org + '/' + str(104) + '.jpg'), (512, 512))/255)
y = Model_800[6](tf.convert_to_tensor(x_train0)).numpy()

y1 = (cv.resize(y.reshape((1024, 1024, 3)), (1500, 1024))*255).astype(np.uint8)
t1 = cv.imread(train_bokeh + '/' + str(104) + '.jpg')
plt.subplot(121)
plt.imshow(y1)
plt.title('output')
plt.subplot(122)
plt.imshow(t1)
plt.title('target')

